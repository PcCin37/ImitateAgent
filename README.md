# flow 主流程使用指南

## 目录定位

本目录为"自动化 UI 交互与推理"核心流程模块，主要用于基于安卓设备自动识别 UI 元素、理解页面、生成交互动作并自动执行，适合需要自动化操作和 UI 解析的场景。

## 主要功能概述

- **自动截图与预处理**：通过 ADB 自动获取安卓设备屏幕截图，利用 SOM 算法进行 UI 元素检测与排序。
- **UI 语义理解**：结合 OCR 及大模型 API，对页面内容和交互组件进行语义理解。
- **交互任务规划与执行**：根据全局任务描述，自动生成子任务，推理出具体交互动作，并通过 ADB 命令自动执行。
- **历史记录与评估**：每一步操作均自动保存历史，支持自动评估交互是否成功，并可追溯操作过程。
- **未加载内容检测**：自动判断界面内容是否加载完全，必要时自动重试截图。

## 主要文件说明

- `final.py`：**主入口脚本**，一键串联截图、UI解析、交互推理、ADB执行、历史记录等全流程。推荐直接运行本文件。
- `som.py`：SOM UI元素检测与排序、图像标注等底层视觉处理。
- `comprehension.py`：页面理解与子任务生成，调用大模型 API 进行语义分析。
- `delete.py`：提取 UI 标签中的 icon 内容，便于后续 JSON 结构化。
- `generate_json_for_folder.py`：将分析结果整理为标准 JSON 文件，供后续推理与执行。
- `interaction_processor.py`：核心交互推理模块，结合历史与当前 UI，推理出下一步操作。
- `output.py`：根据推理结果生成并执行 ADB 命令，实现自动化操作。
- `history.py`：历史记录管理，支持操作追溯、历史摘要与提示生成。
- `compare.py`：自动评估每一步交互是否达成预期目标。
- `check_unloaded_content.py`：检测界面内容是否未加载完全，自动补救。

## 依赖环境

请确保已安装以下依赖（flow目录下 `requirements.txt` 已覆盖）：

- torch、torchvision、easyocr、paddlepaddle、paddleocr
- openai、transformers、ultralytics、opencv-python
- numpy、gradio、timm、einops、pyautogui、screeninfo、uiautomation 等

安装方法：

```bash
pip install -r requirements.txt
```

## 运行前准备

1. **ADB 环境**：需已安装并配置好 adb，且安卓设备已连接并允许调试。
2. **模型权重**：需下载 OmniParser 相关权重至 `weights/` 目录（详见OmniParser 项目 README）。
3. **API Key 配置**：如需调用大模型 API（如 OpenAI），请在相关文件中配置好 API KEY。

## 快速开始

推荐直接运行 `final.py`，体验全流程自动化：

```bash
cd flow
python final.py
```

运行后流程如下：

1. 输入全局任务描述（如"自动点赞并关注"）。
2. 程序自动检测设备、分辨率，截图并分析 UI。
3. 自动推理并执行交互动作，保存每一步历史与评估结果。
4. 每一步结束后可选择是否继续，支持多步自动操作。

## 典型流程示意

1. **截图与预处理**：自动保存截图，SOM 检测 UI 元素，排序并标注。
2. **UI 语义理解**：调用大模型 API，生成页面理解与子任务。
3. **交互推理与执行**：结合历史与当前 UI，推理出下一步操作，自动生成并执行 ADB 命令。
4. **结果评估与历史记录**：自动截图新界面，评估操作是否成功，保存操作历史。
5. **异常处理**：如遇界面未加载完全，自动重试截图与处理。

## 适用场景

- 安卓 App 自动化测试与交互
- UI 视觉理解与交互推理研究
- 基于视觉的智能体自动操作

---

如需更详细的参数说明或二次开发，请参考各模块源码及注释。 